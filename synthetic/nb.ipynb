{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['concept', 'label'])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"concept.pickle\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        print(data.keys())\n",
    "    f.close()\n",
    "except Exception as ex:\n",
    "    print(\"Error during unpickling object\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = data['concept']\n",
    "label = data['label']\n",
    "n = len(label) // 10 * 9\n",
    "concept_train = concept[:n]\n",
    "label_train = label[:n]\n",
    "data_train = np.concatenate((concept_train, label_train.reshape((-1,1))), axis=1)\n",
    "\n",
    "\n",
    "p0 = len(label_train[label_train == 0]) / len(label_train)\n",
    "p1 = 1 - p0\n",
    "\n",
    "concept_a = np.unique(concept_train[:, 0])\n",
    "concept_b = np.unique(concept_train[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_prob(values, data, y):\n",
    "    probs = dict()\n",
    "    data = data[data[:, 2] == y]\n",
    "    for v in values:\n",
    "        probs[v] = len(data[data == v]) / len(data)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa0 = attr_prob(concept_a, data_train, 0)\n",
    "pb0 = attr_prob(concept_b, data_train, 0)\n",
    "pa1 = attr_prob(concept_a, data_train, 1)\n",
    "pb1 = attr_prob(concept_b, data_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5541\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "concept_test = concept[n:]\n",
    "label_test = label[n:]\n",
    "preds = []\n",
    "\n",
    "for (a, b) in concept_test:\n",
    "    prob0 = p0 * pa0[a] * pb0[b]\n",
    "    prob1 = p1 * pa1[a] * pb1[b]\n",
    "    if prob0 > prob1:\n",
    "        preds.append(0)\n",
    "    else:\n",
    "        preds.append(1)\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(preds, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('multibench': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c222fec142c72f5e6af4e9862c69126ee31dbefe1dbc0fa9bc767810b6835b19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
